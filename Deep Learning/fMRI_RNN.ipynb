{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58cde59-761d-4ce8-8beb-6d68f3e33123",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import cuda\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, sampler\n",
    "import torch.nn.functional as F\n",
    "from torch_utils import AverageMeter\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "from torch import optim, cuda, Tensor\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from numpy import inf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import glob\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torchvision import models\n",
    "from torch import optim, cuda, Tensor\n",
    "import tqdm\n",
    "\n",
    "# Data science tools\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "#plt.rcParams['font.size'] = 14\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0023022-c217-41e9-98b3-649bf56c067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_files = glob.glob(\"Fall2021/Class/ML2/FinalProject/data/control/csv/*\")\n",
    "patient_files = glob.glob(\"Fall2021/Class/ML2/FinalProject/data/patient/csv/*\")\n",
    "control_files = control_files\n",
    "patient_files = patient_files\n",
    "control_data = []\n",
    "for csv in control_files:\n",
    "    data = pd.read_csv(csv)\n",
    "    control_data.append(data)\n",
    "control_label = [0] * len(control_data)\n",
    "    \n",
    "patient_data = []\n",
    "for csv in patient_files:\n",
    "    data = pd.read_csv(csv)\n",
    "    patient_data.append(data)\n",
    "patient_label = [1] * len(patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c74c37-04a6-47eb-9a31-3d8919fcc0f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016609</td>\n",
       "      <td>-0.060404</td>\n",
       "      <td>0.057366</td>\n",
       "      <td>-0.039347</td>\n",
       "      <td>0.030656</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>0.014523</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>0.140144</td>\n",
       "      <td>0.005630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020786</td>\n",
       "      <td>-0.000508</td>\n",
       "      <td>0.028165</td>\n",
       "      <td>-0.041512</td>\n",
       "      <td>0.068115</td>\n",
       "      <td>0.043848</td>\n",
       "      <td>0.037309</td>\n",
       "      <td>-0.019145</td>\n",
       "      <td>0.069479</td>\n",
       "      <td>-0.029571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.031675</td>\n",
       "      <td>0.077165</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.039768</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.059069</td>\n",
       "      <td>0.043045</td>\n",
       "      <td>-0.002446</td>\n",
       "      <td>0.013915</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049205</td>\n",
       "      <td>-0.025044</td>\n",
       "      <td>-0.012407</td>\n",
       "      <td>-0.039532</td>\n",
       "      <td>0.023747</td>\n",
       "      <td>0.002535</td>\n",
       "      <td>-0.056310</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>-0.065427</td>\n",
       "      <td>0.056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025445</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>-0.020909</td>\n",
       "      <td>0.031021</td>\n",
       "      <td>0.063386</td>\n",
       "      <td>0.012056</td>\n",
       "      <td>-0.014379</td>\n",
       "      <td>-0.112319</td>\n",
       "      <td>-0.046551</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>-0.001326</td>\n",
       "      <td>0.031366</td>\n",
       "      <td>0.013749</td>\n",
       "      <td>-0.030031</td>\n",
       "      <td>0.008144</td>\n",
       "      <td>-0.020608</td>\n",
       "      <td>-0.058047</td>\n",
       "      <td>0.011946</td>\n",
       "      <td>-0.021855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093377</td>\n",
       "      <td>0.009218</td>\n",
       "      <td>-0.059864</td>\n",
       "      <td>-0.019572</td>\n",
       "      <td>0.092661</td>\n",
       "      <td>-0.049797</td>\n",
       "      <td>-0.030219</td>\n",
       "      <td>0.016441</td>\n",
       "      <td>0.074215</td>\n",
       "      <td>-0.031548</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038555</td>\n",
       "      <td>0.017932</td>\n",
       "      <td>0.089724</td>\n",
       "      <td>0.011744</td>\n",
       "      <td>-0.018033</td>\n",
       "      <td>0.050432</td>\n",
       "      <td>-0.005838</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>-0.040796</td>\n",
       "      <td>-0.005519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090883</td>\n",
       "      <td>-0.008112</td>\n",
       "      <td>0.069968</td>\n",
       "      <td>0.056750</td>\n",
       "      <td>-0.077925</td>\n",
       "      <td>0.046832</td>\n",
       "      <td>-0.038523</td>\n",
       "      <td>-0.007269</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>-0.101524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.093996</td>\n",
       "      <td>-0.073575</td>\n",
       "      <td>0.040138</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.016470</td>\n",
       "      <td>0.006566</td>\n",
       "      <td>-0.038236</td>\n",
       "      <td>0.019450</td>\n",
       "      <td>-0.011511</td>\n",
       "      <td>0.001221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.169327</td>\n",
       "      <td>0.205392</td>\n",
       "      <td>0.058830</td>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.153721</td>\n",
       "      <td>-0.173168</td>\n",
       "      <td>-0.095009</td>\n",
       "      <td>-0.056199</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.086760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136907</td>\n",
       "      <td>0.246497</td>\n",
       "      <td>0.133358</td>\n",
       "      <td>0.256638</td>\n",
       "      <td>-0.026082</td>\n",
       "      <td>0.047472</td>\n",
       "      <td>0.150622</td>\n",
       "      <td>-0.129704</td>\n",
       "      <td>0.084983</td>\n",
       "      <td>0.016470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.210065</td>\n",
       "      <td>-0.107279</td>\n",
       "      <td>0.061673</td>\n",
       "      <td>-0.165779</td>\n",
       "      <td>-0.029421</td>\n",
       "      <td>-0.035107</td>\n",
       "      <td>-0.054149</td>\n",
       "      <td>0.113709</td>\n",
       "      <td>0.009631</td>\n",
       "      <td>-0.054883</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.090939</td>\n",
       "      <td>-0.079389</td>\n",
       "      <td>0.155594</td>\n",
       "      <td>0.237894</td>\n",
       "      <td>0.084489</td>\n",
       "      <td>0.085827</td>\n",
       "      <td>-0.091940</td>\n",
       "      <td>0.074068</td>\n",
       "      <td>0.140173</td>\n",
       "      <td>-0.076498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.045999</td>\n",
       "      <td>-0.022692</td>\n",
       "      <td>-0.103410</td>\n",
       "      <td>-0.096906</td>\n",
       "      <td>-0.015988</td>\n",
       "      <td>0.151825</td>\n",
       "      <td>0.015116</td>\n",
       "      <td>0.040163</td>\n",
       "      <td>-0.092147</td>\n",
       "      <td>-0.051808</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069647</td>\n",
       "      <td>0.075088</td>\n",
       "      <td>-0.106701</td>\n",
       "      <td>0.077400</td>\n",
       "      <td>-0.166083</td>\n",
       "      <td>-0.035031</td>\n",
       "      <td>-0.158438</td>\n",
       "      <td>0.052027</td>\n",
       "      <td>-0.107778</td>\n",
       "      <td>0.060899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.023614</td>\n",
       "      <td>0.132421</td>\n",
       "      <td>-0.028188</td>\n",
       "      <td>0.023664</td>\n",
       "      <td>0.010282</td>\n",
       "      <td>0.009604</td>\n",
       "      <td>-0.023253</td>\n",
       "      <td>-0.006351</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.053126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063886</td>\n",
       "      <td>-0.071344</td>\n",
       "      <td>0.130591</td>\n",
       "      <td>-0.077110</td>\n",
       "      <td>-0.077975</td>\n",
       "      <td>0.091394</td>\n",
       "      <td>-0.008631</td>\n",
       "      <td>-0.037828</td>\n",
       "      <td>0.075315</td>\n",
       "      <td>0.051358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.052527</td>\n",
       "      <td>-0.023406</td>\n",
       "      <td>0.046043</td>\n",
       "      <td>-0.049010</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>-0.084909</td>\n",
       "      <td>0.037384</td>\n",
       "      <td>0.029210</td>\n",
       "      <td>-0.030236</td>\n",
       "      <td>-0.017744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037081</td>\n",
       "      <td>0.077065</td>\n",
       "      <td>0.033452</td>\n",
       "      <td>0.020686</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.056025</td>\n",
       "      <td>0.022553</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.066391</td>\n",
       "      <td>0.056756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.016609 -0.060404  0.057366 -0.039347  0.030656  0.007839  0.014523   \n",
       "1   0.027514  0.031675  0.077165  0.002600  0.039768  0.001546  0.059069   \n",
       "2   0.025445  0.021967 -0.020909  0.031021  0.063386  0.012056 -0.014379   \n",
       "3   0.093377  0.009218 -0.059864 -0.019572  0.092661 -0.049797 -0.030219   \n",
       "4   0.090883 -0.008112  0.069968  0.056750 -0.077925  0.046832 -0.038523   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "95  0.169327  0.205392  0.058830  0.000814  0.153721 -0.173168 -0.095009   \n",
       "96  0.210065 -0.107279  0.061673 -0.165779 -0.029421 -0.035107 -0.054149   \n",
       "97 -0.045999 -0.022692 -0.103410 -0.096906 -0.015988  0.151825  0.015116   \n",
       "98 -0.023614  0.132421 -0.028188  0.023664  0.010282  0.009604 -0.023253   \n",
       "99 -0.052527 -0.023406  0.046043 -0.049010  0.026245 -0.084909  0.037384   \n",
       "\n",
       "          7         8         9   ...        90        91        92        93  \\\n",
       "0   0.015690  0.140144  0.005630  ... -0.020786 -0.000508  0.028165 -0.041512   \n",
       "1   0.043045 -0.002446  0.013915  ... -0.049205 -0.025044 -0.012407 -0.039532   \n",
       "2  -0.112319 -0.046551  0.074074  ...  0.005200 -0.001326  0.031366  0.013749   \n",
       "3   0.016441  0.074215 -0.031548  ...  0.038555  0.017932  0.089724  0.011744   \n",
       "4  -0.007269  0.006600 -0.101524  ...  0.093996 -0.073575  0.040138  0.004603   \n",
       "..       ...       ...       ...  ...       ...       ...       ...       ...   \n",
       "95 -0.056199  0.077100  0.086760  ...  0.136907  0.246497  0.133358  0.256638   \n",
       "96  0.113709  0.009631 -0.054883  ... -0.090939 -0.079389  0.155594  0.237894   \n",
       "97  0.040163 -0.092147 -0.051808  ...  0.069647  0.075088 -0.106701  0.077400   \n",
       "98 -0.006351 -0.000831  0.053126  ...  0.063886 -0.071344  0.130591 -0.077110   \n",
       "99  0.029210 -0.030236 -0.017744  ... -0.037081  0.077065  0.033452  0.020686   \n",
       "\n",
       "          94        95        96        97        98        99  \n",
       "0   0.068115  0.043848  0.037309 -0.019145  0.069479 -0.029571  \n",
       "1   0.023747  0.002535 -0.056310  0.007358 -0.065427  0.056800  \n",
       "2  -0.030031  0.008144 -0.020608 -0.058047  0.011946 -0.021855  \n",
       "3  -0.018033  0.050432 -0.005838  0.002993 -0.040796 -0.005519  \n",
       "4   0.016470  0.006566 -0.038236  0.019450 -0.011511  0.001221  \n",
       "..       ...       ...       ...       ...       ...       ...  \n",
       "95 -0.026082  0.047472  0.150622 -0.129704  0.084983  0.016470  \n",
       "96  0.084489  0.085827 -0.091940  0.074068  0.140173 -0.076498  \n",
       "97 -0.166083 -0.035031 -0.158438  0.052027 -0.107778  0.060899  \n",
       "98 -0.077975  0.091394 -0.008631 -0.037828  0.075315  0.051358  \n",
       "99  0.020794  0.056025  0.022553 -0.002642 -0.066391  0.056756  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9216a18-6edf-4fe6-9914-4fef1d67580f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 100, 100) (516,)\n"
     ]
    }
   ],
   "source": [
    "train_x = np.squeeze(np.array((control_data + patient_data)))\n",
    "train_y = np.asarray(control_label + patient_label)\n",
    "print(train_x.shape,train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0d99aed-c31b-44b9-800f-7d670f84de95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(412, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.2)\n",
    "train_x = np.expand_dims(train_x, axis = 1 )\n",
    "val_x = np.expand_dims(val_x, axis = 1)\n",
    "print(train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd892c5-4f08-40e0-99dd-7c4bb4d84156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets organization\n",
    "batch_size = 10\n",
    "\n",
    "# Transfer the data from numpy to tensor\n",
    "data = {\n",
    "    'train':\n",
    "    TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y).float()),\n",
    "    'valid':\n",
    "    TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y).float())\n",
    "}\n",
    "\n",
    "# Dataloader iterators, make sure to shuffle\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True, num_workers=1),\n",
    "    'valid': DataLoader(data['valid'], batch_size=batch_size, shuffle=True, num_workers=1)       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7483e737-542d-4de3-a4b8-fc252a3d224f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RNN Model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b2de65c-a856-4e80-a9ce-f2c83f82b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(100,3, 3 ,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "89c02311-edc2-4d6c-90b2-7189cd0be3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,\n",
    "          criterion,\n",
    "          optimizer,\n",
    "          train_loader,\n",
    "          valid_loader,\n",
    "          save_file_name,\n",
    "          max_epochs_stop=3,\n",
    "          n_epochs=10,\n",
    "          print_every=1):\n",
    "    epochs_no_improve = 0\n",
    "    valid_loss_min = np.Inf\n",
    "\n",
    "    valid_max_acc = 0\n",
    "    history = []\n",
    "\n",
    "    # Number of epochs already trained (if using loaded in model weights)\n",
    "    try:\n",
    "        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n",
    "    except:\n",
    "        model.epochs = 0\n",
    "        print(f'Starting Training from Scratch.\\n')\n",
    "\n",
    "    overall_start = timer()\n",
    "\n",
    "    # Main loop\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        # keep track of training and validation loss each epoch\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        train_acc = 0\n",
    "        valid_acc = 0\n",
    "       \n",
    "\n",
    "        # Set to training\n",
    "  \n",
    "        model.train()\n",
    "        \n",
    "        start = timer()\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (data, target) in enumerate(train_loader):\n",
    "            \n",
    "            # Tensors to gpu\n",
    "            \n",
    "            if train_on_gpu:\n",
    "                model = model.cuda()\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "           \n",
    "\n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Get your output from your model\n",
    "          \n",
    "            model = model.float()\n",
    "            output = model(data.float())\n",
    "\n",
    "            # Loss and backpropagation of gradients\n",
    "            \n",
    "            loss = criterion(output, target.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            \n",
    "\n",
    "\n",
    "            # Calculate accuracy by finding max log probability\n",
    "            \n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "           \n",
    "\n",
    "            # Need to convert correct tensor from int to float to average\n",
    "            \n",
    "            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n",
    "            \n",
    "\n",
    "            # Multiply average accuracy times the number of examples in batch\n",
    "            \n",
    "            train_acc += accuracy.item() * data.size(0)\n",
    "            \n",
    "\n",
    "            # Track training progress\n",
    "            print(\n",
    "                f'Epoch: {epoch}\\t{100 * (ii + 1) / len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n",
    "                end='\\r')\n",
    "\n",
    "        # After training loops ends, start validation\n",
    "        else:\n",
    "            model.epochs += 1\n",
    "\n",
    "            # Don't need to keep track of gradients\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # Set to evaluation mode\n",
    "                \n",
    "                model.eval()\n",
    "                \n",
    "\n",
    "                # Validation loop\n",
    "                for data, target in valid_loader:\n",
    "                    # Tensors to gpu\n",
    "                    \n",
    "                    if train_on_gpu:\n",
    "                        model = model.cuda()\n",
    "                        data, target = data.cuda(), target.cuda()\n",
    "                    \n",
    "                    # Forward pass                    \n",
    "                    model = model.float()\n",
    "                    output = model(data.float())\n",
    "                    \n",
    "                    # Validation loss\n",
    "                    loss = criterion(output, target.long())\n",
    "                    \n",
    "                    # Multiply average loss times the number of examples in batch\n",
    "                    valid_loss += loss.item() * data.size(0)\n",
    "                    \n",
    "                    # Calculate validation accuracy\n",
    "                    _, pred = torch.max(output, dim=1)\n",
    "                    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "                    accuracy = torch.mean(\n",
    "                        correct_tensor.type(torch.FloatTensor))\n",
    "                    \n",
    "                    # Multiply average accuracy times the number of examples\n",
    "                    valid_acc += accuracy.item() * data.size(0)\n",
    "                    \n",
    "\n",
    "                # Calculate average losses\n",
    "                train_loss = train_loss / len(train_loader.dataset)\n",
    "                valid_loss = valid_loss / len(valid_loader.dataset)\n",
    "                \n",
    "\n",
    "                # Calculate average accuracy\n",
    "                train_acc = train_acc / len(train_loader.dataset)\n",
    "                valid_acc = valid_acc / len(valid_loader.dataset)\n",
    "                history.append([train_loss, valid_loss, train_acc, valid_acc])\n",
    "\n",
    "                # Print training and validation results\n",
    "                if (epoch + 1) % print_every == 0:\n",
    "                    print(\n",
    "                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n",
    "                    )\n",
    "                    print(\n",
    "                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n",
    "                    )\n",
    "\n",
    "                # Save the model if validation loss decreases\n",
    "                if valid_loss < valid_loss_min:\n",
    "                    # Save model\n",
    "                    torch.save(model.state_dict(), save_file_name)\n",
    "                    # Track improvement\n",
    "                    epochs_no_improve = 0\n",
    "                    valid_loss_min = valid_loss\n",
    "                    valid_best_acc = valid_acc\n",
    "                    best_epoch = epoch\n",
    "\n",
    "                # Otherwise increment count of epochs with no improvement\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    # Trigger early stopping\n",
    "                    if epochs_no_improve >= max_epochs_stop:\n",
    "                        print(\n",
    "                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n",
    "                        )\n",
    "                        total_time = timer() - overall_start\n",
    "                        print(\n",
    "                            f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "                        )\n",
    "\n",
    "                        # Load the best state dict                        \n",
    "                        model.load_state_dict(torch.load(save_file_name))\n",
    "                        \n",
    "                        # Attach the optimizer\n",
    "                        model.optimizer = optimizer\n",
    "\n",
    "                        # Format history\n",
    "                        history = pd.DataFrame(\n",
    "                            history,\n",
    "                            columns=[\n",
    "                                'train_loss', 'valid_loss', 'train_acc',\n",
    "                                'valid_acc'\n",
    "                            ])\n",
    "                        return model, history\n",
    "\n",
    "    # Attach the optimizer\n",
    "    model.optimizer = optimizer\n",
    "    # Record overall time and print out stats\n",
    "    total_time = timer() - overall_start\n",
    "    print(\n",
    "        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_best_acc:.2f}%'\n",
    "    )\n",
    "    print(\n",
    "        f'{total_time:.2f} total seconds elapsed. {total_time / (epoch+1):.2f} seconds per epoch.'\n",
    "    )\n",
    "    # Format history\n",
    "    history = pd.DataFrame(\n",
    "        history,\n",
    "        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f3d3336-d1b6-4f42-8545-c8314cd95e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training from Scratch.\n",
      "\n",
      "Epoch: 0\t100.00% complete. 1.29 seconds elapsed in epoch.\n",
      "Epoch: 0 \tTraining Loss: 0.6735 \tValidation Loss: 0.6677\n",
      "\t\tTraining Accuracy: 61.65%\t Validation Accuracy: 61.54%\n",
      "Epoch: 1\t100.00% complete. 1.27 seconds elapsed in epoch.\n",
      "Epoch: 1 \tTraining Loss: 0.6623 \tValidation Loss: 0.6663\n",
      "\t\tTraining Accuracy: 64.56%\t Validation Accuracy: 61.54%\n",
      "Epoch: 2\t100.00% complete. 1.26 seconds elapsed in epoch.\n",
      "Epoch: 2 \tTraining Loss: 0.6512 \tValidation Loss: 0.6703\n",
      "\t\tTraining Accuracy: 64.56%\t Validation Accuracy: 61.54%\n",
      "Epoch: 3\t100.00% complete. 1.26 seconds elapsed in epoch.\n",
      "Epoch: 3 \tTraining Loss: 0.6554 \tValidation Loss: 0.6736\n",
      "\t\tTraining Accuracy: 64.56%\t Validation Accuracy: 61.54%\n",
      "Epoch: 4\t100.00% complete. 1.35 seconds elapsed in epoch.\n",
      "Epoch: 4 \tTraining Loss: 0.6712 \tValidation Loss: 0.6679\n",
      "\t\tTraining Accuracy: 64.56%\t Validation Accuracy: 61.54%\n",
      "\n",
      "Early Stopping! Total epochs: 4. Best epoch: 1 with loss: 0.67 and acc: 61.54%\n",
      "7.18 total seconds elapsed. 1.44 seconds per epoch.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = .1)\n",
    "\n",
    "model, history = train(model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dataloaders['train'], \n",
    "    dataloaders['valid'],\n",
    "    save_file_name=save_file_name,\n",
    "    max_epochs_stop=3,\n",
    "    n_epochs=500,\n",
    "    print_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7338513e-d0d1-4c4f-b81a-44d03626a982",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
